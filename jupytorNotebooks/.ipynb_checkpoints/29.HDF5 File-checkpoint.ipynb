{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 29. HDF5 File Format (Hierarchical Data Format)\n",
    "\n",
    "- h5py 패키지는 Python에서 HDF5 바이너리 데이터 포맷을 사용하기 위한 인터페이스 패키지.\n",
    "- H5F5 포맷은 많은 양의 데이터를 카테고리 또는 속성별로 데이터를 나눠서 저장 할 수 있을 뿐만 아니라 numpy를 이용하여 데이터에 접근하여 사용할 수 있다.\n",
    "\n",
    "<img src=\"hdf5.png\" width=\"200\"/>\n",
    "\n",
    "- HDF5 파일은 배열과 같은 데이터 모음인 데이터 세트와 데이터 세트 및 기타 그룹을 보관하는 폴더와 같은 컨테이너인 그룹의 두 가지 종류의 개체를 위한 컨테이너입니다.\n",
    "\n",
    "- 그룹은 dictionary처럼 작동하고 dataset는 NumPy 배열처럼 작동합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 설치\n",
    "conda install h5py  또는,\n",
    "\n",
    "pip install h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "try:\n",
    "    os.remove('FileA.hdf5')\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "f = h5py.File('FileA.hdf5', 'w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 그룹/하위그룹 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['groupA']>\n",
      "<KeysViewHDF5 ['subGroupB']>\n"
     ]
    }
   ],
   "source": [
    "g = f.create_group(\"groupA\")\n",
    "sub = g.create_group(\"subGroupB\")\n",
    "\n",
    "print (f.keys())\n",
    "print (g.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## group 내에 dataset 생성\n",
    "\n",
    "- g.create_dataset(name_of_dataset, initial value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = g.create_dataset(\"dataset1\", data = np.arange(20))  \n",
    "dataset2 = g.create_dataset(\"dataset2\", data= np.random.randint(0, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['dataset1', 'dataset2', 'subGroupB']>\n",
      "<HDF5 dataset \"dataset1\": shape (20,), type \"<i8\">\n",
      "<HDF5 dataset \"dataset2\": shape (), type \"<i8\">\n",
      "<HDF5 group \"/groupA/subGroupB\" (0 members)>\n"
     ]
    }
   ],
   "source": [
    "print(g.keys())\n",
    "\n",
    "for k in g.keys():\n",
    "    dataset = g[k]\n",
    "    print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 하위 그룹의 dataset  생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = sub.create_dataset(\"dataset3\", data = np.arange(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['dataset3']>\n",
      "<HDF5 dataset \"dataset3\": shape (20,), type \"<i8\">\n",
      "int64\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n"
     ]
    }
   ],
   "source": [
    "print(sub.keys())\n",
    "\n",
    "for k in sub.keys():\n",
    "    dataset = sub[k]\n",
    "    print (dataset)\n",
    "    print (dataset.dtype)\n",
    "    print (dataset[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실제 data example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list_classes\n",
      "test_set_x\n",
      "test_set_y\n",
      "<HDF5 dataset \"list_classes\": shape (2,), type \"|S7\">\n",
      "<HDF5 dataset \"test_set_x\": shape (50, 64, 64, 3), type \"|u1\">\n",
      "<HDF5 dataset \"test_set_y\": shape (50,), type \"<i8\">\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(\"test_catvnoncat.h5\", 'r') as test_dataset:\n",
    "    for k in test_dataset.keys():\n",
    "        print(k)\n",
    "    \n",
    "    print(test_dataset[\"list_classes\"])\n",
    "    print(test_dataset[\"test_set_x\"])\n",
    "    print(test_dataset[\"test_set_y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = h5py.File(\"test_catvnoncat.h5\", 'r')\n",
    "X_train = np.array(train_dataset[\"test_set_x\"])\n",
    "y_train = np.array(train_dataset[\"test_set_y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 64, 64, 3) (50,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
